# JARVIS Voice Assistant - Complete Capabilities (Phase 1 & 2)

## ğŸ™ï¸ Voice Interaction

### Input Methods
- **Hotkey Activation**: Press `Ctrl+Space` to start listening
- **Voice Recognition**: Whisper base model for accurate speech-to-text
- **Visual Feedback**: Siri-like animated UI showing listening/processing states

### Output
- **Text-to-Speech**: Google TTS with natural voice
- **Visual UI**: Animated overlay showing assistant status

---

## ğŸ§  Intelligence (Phase 1: LLM Integration)

### Hybrid Processing
- **Smart Routing**: Automatically chooses between fast rules or intelligent LLM
- **Rule-Based**: Simple commands (open/close apps) - instant response
- **LLM-Powered**: Complex queries using Ollama + functiongemma:270m

### LLM Features
- Natural language understanding
- Context-aware responses
- Conversational personality (JARVIS)
- Graceful fallback if LLM unavailable

---

## ğŸ› ï¸ Tools & Capabilities (Phase 2: Tool Calling)

### 1. Application Control (Rule-Based)
```
âœ“ "open firefox"
âœ“ "launch chrome"
âœ“ "close firefox"
âœ“ "quit chrome"
```

**Supported Apps:**
- Firefox, Chrome, Chromium
- VS Code, Sublime Text, Gedit
- Terminal, Nautilus (file manager)
- VLC, Spotify
- LibreOffice, GIMP
- And more (configurable in `config/commands.yaml`)

---

### 2. Filesystem Operations (LLM Tools)

#### List Files
```
âœ“ "list all files in the current directory"
âœ“ "show me all python files"
âœ“ "list files in /home/user/Documents"
```

**Tool**: `list_files`
- Pattern matching (*.py, *.txt, etc.)
- Recursive search option
- Returns file names, paths, types, sizes

#### Read Files
```
âœ“ "read the contents of config.yaml"
âœ“ "show me what's in README.md"
âœ“ "read the first 50 lines of main.py"
```

**Tool**: `read_file`
- Reads text files
- Configurable line limits
- UTF-8 encoding support

#### Search Files
```
âœ“ "find all files named config.yaml"
âœ“ "search for python files in my home directory"
âœ“ "locate all README files"
```

**Tool**: `search_files`
- Recursive directory search
- Pattern-based matching
- Returns up to 20 results

---

### 3. System Information (LLM Tools)

#### System Stats
```
âœ“ "what's my CPU usage?"
âœ“ "how much RAM do I have?"
âœ“ "show me disk usage"
âœ“ "tell me about my system"
```

**Tool**: `get_system_info`
- CPU usage percentage
- CPU count and frequency
- Memory (total, used, available)
- Disk space (total, used, free)

#### Process Management
```
âœ“ "show me running processes"
âœ“ "list all firefox processes"
âœ“ "what processes are using the most CPU?"
```

**Tool**: `get_processes`
- List running processes
- Filter by name
- Shows PID, CPU%, memory%
- Returns top 10 by default

#### Safe Command Execution
```
âœ“ "run ls command"
âœ“ "execute pwd"
âœ“ "run df -h"
```

**Tool**: `execute_command`
- **Whitelist only**: ls, cat, grep, find, head, tail, wc, echo, pwd, whoami, date, df, du, ps, top, free
- 5-second timeout
- Captures stdout/stderr
- **Safe**: No destructive commands allowed

---

### 4. Web Access (LLM Tools)

#### Web Search
```
âœ“ "search the web for Python tutorials"
âœ“ "look up Linux commands"
âœ“ "find information about Docker"
```

**Tool**: `search_web`
- Uses DuckDuckGo API
- Returns titles, snippets, URLs
- Up to 5 results
- No API key required

#### Fetch Web Content
```
âœ“ "fetch content from example.com"
âœ“ "get the text from this URL: https://..."
```

**Tool**: `fetch_url`
- Downloads web page content
- Returns text content
- 2000 character limit (configurable)
- 10-second timeout

---

## ğŸ¯ Example Use Cases

### Simple Commands (Rules - Fast)
```
User: "open firefox"
â†’ Uses: Rule-based parser
â†’ Speed: <100ms
â†’ Result: Firefox opens
```

### Complex Queries (LLM - Intelligent)
```
User: "how many python files are in this directory?"
â†’ Uses: LLM + list_files tool
â†’ Speed: ~3s
â†’ Result: "I found 15 Python files in the current directory"
```

### Multi-Step Tasks (LLM + Multiple Tools)
```
User: "find all python files and tell me about my CPU"
â†’ Uses: LLM + list_files + get_system_info
â†’ Speed: ~5s
â†’ Result: Lists files + reports CPU usage
```

### System Queries
```
User: "what's my system status?"
â†’ Uses: LLM + get_system_info
â†’ Result: "Your CPU is at 25%, you have 8GB RAM with 4GB available, and 120GB free disk space"
```

---

## ğŸ”§ Configuration

### Customizable Settings (`config/config.yaml`)

**Audio:**
- Sample rate, channels
- Recording duration

**Speech-to-Text:**
- Whisper model (tiny/base/small/medium)
- Device (CPU/GPU)
- Language

**LLM:**
- Enable/disable
- Model selection
- Temperature (creativity)
- Max tokens (response length)
- Timeout
- Fallback options

**TTS:**
- Language
- Voice variant

**Hotkey:**
- Customizable key combination

---

## ğŸ“Š Performance

| Operation | Speed | Notes |
|-----------|-------|-------|
| Simple command (rules) | <100ms | "open firefox" |
| LLM query (no tools) | 2-3s | "tell me a joke" |
| LLM + 1 tool | 3-5s | "list python files" |
| LLM + multiple tools | 5-10s | Multi-step tasks |
| STT (5 sec audio) | ~1s | Whisper base model |
| TTS generation | ~1s | Google TTS |

---

## ğŸ›¡ï¸ Safety Features

### Tool Safety
- **Whitelisted commands only** - No rm, sudo, or destructive operations
- **Timeouts** - All operations have time limits
- **File size limits** - Prevents reading huge files
- **Error handling** - Graceful failures, no crashes
- **Sandboxed execution** - Tools run in controlled environment

### LLM Safety
- **Fallback to rules** - If LLM fails, rules still work
- **Timeout protection** - Won't hang indefinitely
- **Local processing** - Ollama runs on your machine
- **No data sent to cloud** - Everything stays local

---

## ğŸš€ What's Next

### Phase 3: Wake Word Detection (Optional)
- "JARVIS" wake word
- Hands-free activation
- Continuous listening mode

### Phase 4: MCP Client (Advanced)
- Connect to external tool servers
- Expanded tool ecosystem
- Git, database, API integrations

### Phase 5: Context & Memory
- Remember previous conversations
- Multi-turn interactions
- Context-aware responses

---

## ğŸ“ Quick Reference

### Voice Commands You Can Try

**App Control:**
- "open firefox"
- "close chrome"
- "launch vs code"

**File Operations:**
- "list all python files"
- "read the README file"
- "find all config files"

**System Info:**
- "what's my CPU usage?"
- "how much RAM do I have?"
- "show me running processes"

**Web:**
- "search the web for Python tutorials"
- "look up Linux commands"

**Complex:**
- "list all python files and tell me how many there are"
- "show me my system status"
- "find all text files in my home directory"

---

## ğŸ“ How It Works

### Architecture
```
Voice Input (Ctrl+Space)
    â†“
Whisper STT (speech â†’ text)
    â†“
Smart Router (simple or complex?)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Rules     â”‚     LLM      â”‚
â”‚   (fast)    â”‚  (smart)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“            â†“
    Execute      Tool Calls
                     â†“
                 8 Tools
                     â†“
    Response â† Format Results
         â†“
    Google TTS (text â†’ speech)
         â†“
    Voice Output + UI
```

### Intelligence Levels

**Level 1: Rule-Based** (v0)
- Pattern matching
- Keyword detection
- Fast but limited

**Level 2: LLM-Powered** (Phase 1)
- Natural language understanding
- Conversational responses
- Intelligent but no actions

**Level 3: Tool Calling** (Phase 2) â† **You are here!**
- LLM can use tools
- Autonomous task execution
- Multi-step reasoning

**Level 4: Agentic** (Future)
- Long-term memory
- Complex planning
- External integrations

---

## ğŸ’¡ Tips

1. **Speak clearly** - Better recognition with clear speech
2. **Be specific** - "list python files" vs "show me files"
3. **Use natural language** - LLM understands conversational queries
4. **Check logs** - `logs/lva.log` for debugging
5. **Experiment** - Try complex multi-step requests!

---

**Total Capabilities: 20+ distinct functions across 8 tools + app control + system queries**
