# aichat Configuration for JARVIS Script Generation

# This is a sample configuration for aichat to work with JARVIS
# Copy this to ~/.config/aichat/config.yaml

# Model Configuration
# Use local Ollama for privacy and speed (recommended)
model: ollama:deepseek-r1:1.5b

# Alternative models (uncomment to use):
# model: ollama:llama3.2              # More capable local model
# model: ollama:codellama             # Specialized for code
# model: openai:gpt-4                 # Most capable (needs API key)
# model: claude:claude-3-sonnet       # Great balance (needs API key)

# Temperature (creativity vs consistency)
# 0.0 = very consistent, 1.0 = very creative
temperature: 0.3  # Lower for script generation (more deterministic)

# Save conversation history
save: true

# Highlight code in output
highlight: true

# Stream responses (set to false for JARVIS integration)
stream: false

# Wrap text at terminal width
wrap: auto

# Maximum tokens in response
max_output_tokens: 2048

# For Ollama (local AI)
clients:
  - type: ollama
    api_base: http://localhost:11434
    
# For OpenAI (if using)
# clients:
#   - type: openai
#     api_key: YOUR_API_KEY_HERE
    
# For Anthropic Claude (if using)
# clients:
#   - type: claude
#     api_key: YOUR_API_KEY_HERE

# Custom roles for script generation
roles:
  script_generator:
    name: Script Generator
    prompt: |
      You are an expert script writer. Generate clean, production-ready scripts
      with proper error handling and comments. Output ONLY the script code
      without explanations or markdown formatting.
      
  bash_expert:
    name: Bash Expert
    prompt: |
      You are a bash scripting expert. Write efficient, safe bash scripts
      with proper error handling, input validation, and clear comments.
      
  python_expert:
    name: Python Expert
    prompt: |
      You are a Python expert. Write clean, Pythonic code following PEP 8,
      with proper error handling, type hints, and docstrings.
