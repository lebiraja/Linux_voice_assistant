# Linux Voice AI Assistant Configuration

# Audio Settings
audio:
  sample_rate: 16000
  channels: 1
  chunk_size: 1024
  max_recording_seconds: 10
  
# Speech-to-Text (Whisper)
stt:
  model_name: "base"  # Changed from 'tiny' for better accuracy
  device: "cpu"
  compute_type: "int8"
  language: "en"
  
# Text-to-Speech (Piper)
tts:
  model_name: "en_US-lessac-medium"
  speaker: 0
  length_scale: 1.0
  noise_scale: 0.667
  noise_w: 0.8

# LLM Configuration (Ollama)
llm:
  enabled: true
  provider: "ollama"
  base_url: "http://localhost:11434"  # Works with Docker host networking
  model: "qwen3:4b"  # Excellent tool calling support (already installed)
  temperature: 0.3    # Low for tool calling accuracy
  max_tokens: 512     # Sufficient for tool calls
  timeout: 30
  fallback_to_rules: true

# AI Script Generation (aichat)
aichat:
  enabled: true
  model: "ollama:qwen3:4b"  # Same model for consistency
  timeout: 60  # Script generation timeout in seconds
  max_script_execution_time: 300  # 5 minutes max for script execution
  auto_execute: true  # Automatically execute generated scripts (user preference)
  working_directory: null  # Default to current directory, or specify a path

# Conversation Mode
conversation:
  enabled: true
  max_history: 10  # Number of exchanges to remember
  context_window: 5  # Number of recent exchanges to include in prompts
  context_file: "user_context.json"  # File to store user preferences and context
  
# Hotkey Configuration
hotkey:
  combination: "<ctrl>+<space>"
  
# Logging
logging:
  level: "INFO"
  file: "logs/lva.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5

# Wake Word Detection
wake_word:
  enabled: true
  model: "hey_jarvis"  # Pre-trained model: hey_jarvis, alexa, hey_mycroft
  threshold: 0.35      # Detection threshold (0.0-1.0) - lowered for better sensitivity
  chunk_size: 1280     # Audio chunk size for processing
  vad_threshold: 0.0   # Voice activity detection threshold
  
# Paths
paths:
  temp_audio: "temp"
  models: "models"
  logs: "logs"
